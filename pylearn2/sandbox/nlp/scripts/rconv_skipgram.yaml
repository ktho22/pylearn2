
!obj:pylearn2.train.Train {
  dataset: !obj:pylearn2.sandbox.nlp.datasets.rnn_skipgram.H5RnnSkipgram {
    path: '/data/lisatmp3/pougetj/double_filtered_binarized_corpus_train.h5',
    node: '/double_filtered_binarized_corpus_train',
    which_set: 'train',
    frame_length: &n 7,
    stop: 100000000,
    _iter_num_batches: 20,
    X_labels: &l 15000, 
    load_to_memory: True,
    cache_size: 10000,
    cache_delta: 1000
  },
  model: !obj:pylearn2.models.mlp.MLP {
    input_space: !obj:pylearn2.sandbox.rnn.space.SequenceSpace {
      space: !obj:pylearn2.space.IndexSpace {
        dim: 1,
        max_labels: &char_labels 213, # Number of different characters + 1 for eow
      },
    },
    target_source: ['target0', 'target1', 'target2', 'target3', 'target4', 'target5' ],
    layers: [
     !obj:pylearn2.sandbox.nlp.models.mlp.ProjectionLayer {
        layer_name: 'projection',
        dim: 620,
        irange: 0.01
       },
     !obj:pylearn2.sandbox.rnn.models.rnn.RecursiveConvolutionalLayer {
        layer_name: 'rconv_layer',
        dim: 620,
        irange: 0.01,
        indices: [-1]
      },
     !obj:pylearn2.models.mlp.CompositeLayer {
        layer_name: 'composite_layer',
        layers: 
        [!obj:pylearn2.sandbox.nlp.models.mlp.Softmax {
            n_classes: *l,
            layer_name: 'h0',
            irange: 0.01,
            binary_target_dim: 1
          },
          !obj:pylearn2.sandbox.nlp.models.mlp.Softmax {
           n_classes: *l,
            layer_name: 'h1',
            irange: 0.01,
            binary_target_dim: 1
          },
          !obj:pylearn2.sandbox.nlp.models.mlp.Softmax {
            n_classes: *l,
            layer_name: 'h2',
            irange: 0.01,
            binary_target_dim: 1
          },
          !obj:pylearn2.sandbox.nlp.models.mlp.Softmax {
            n_classes: *l,
            layer_name: 'h3',
            irange: 0.01,
            binary_target_dim: 1
          },
          !obj:pylearn2.sandbox.nlp.models.mlp.Softmax {
            n_classes: *l,
            layer_name: 'h4',
            irange: 0.01,
            binary_target_dim: 1
          },
          !obj:pylearn2.sandbox.nlp.models.mlp.Softmax {
            n_classes: *l,
            layer_name: 'h5',
            irange: 0.01,
            binary_target_dim: 1
          }
        ]
      }
    ],
  },
  algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
    batch_size: 32, #256,
    learning_rate: .0001,
    learning_rule: !obj:pylearn2.training_algorithms.learning_rule.AdaDelta {},
    monitoring_dataset: {
     'valid': !obj:pylearn2.sandbox.nlp.datasets.rnn_skipgram.H5RnnSkipgram {
        path: '/data/lisatmp3/pougetj/double_filtered_binarized_corpus_valid.h5',
        node: '/double_filtered_binarized_corpus_valid',
        which_set: 'valid',
        frame_length: *n,
        stop: 5000,
        _iter_num_batches: 30,
        X_labels: *l,
        load_to_memory: True
      },
     'train': !obj:pylearn2.sandbox.nlp.datasets.rnn_skipgram.H5RnnSkipgram {
        path: '/data/lisatmp3/pougetj/double_filtered_binarized_corpus_train.h5',
        node: '/double_filtered_binarized_corpus_train',
        which_set: 'train',
        frame_length: *n,
        stop: 1000,
        _iter_num_batches: 20,
        X_labels: *l,
        load_to_memory: True
      },
    },
    cost: !obj:pylearn2.sandbox.rnn.costs.gradient_clipping.GradientClipping {
      clipping_value: 1,
      cost: !obj:pylearn2.costs.mlp.Default {}
    }

  },
  #extensions: [
  #     !obj:pylearn2.train_extensions.WordRelationship {
  #       vocab: "/data/lisatmp3/pougetj/vocab.pkl",
  #       questions: "/data/lisatmp3/pougetj/questions-words.txt",
  #       vocab_size: *l,
  #       UNK: 1,
  #       n_batches: 4, 
  #       use_chars: True,
  #       char_dict_path: '/data/lisa/data/word2vec/char_vocab.pkl',
  #     }
  #],
  save_path: 'result/rnn_skipgram_factored.pkl',
  save_freq: 1,
}
