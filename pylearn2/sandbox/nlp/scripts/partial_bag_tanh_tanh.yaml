!obj:pylearn2.train.Train {
  dataset: !obj:pylearn2.sandbox.nlp.datasets.translationChars.TranslationChars {
    which_set: 'train',
  },
  model: !obj:pylearn2.models.mlp.MLP {
    input_space: !obj:pylearn2.sandbox.rnn.space.SequenceSpace {
      space: !obj:pylearn2.space.IndexSpace {
        dim: 1,
        max_labels: &labels 145,
      },
    },
    layers: [
      !obj:pylearn2.sandbox.nlp.models.mlp.ProjectionLayer {
        layer_name: 'projection_layer',
        dim: &n_hids %(n_hids)i,
        irange: 0.01,
      },
      !obj:pylearn2.sandbox.nlp.models.mlp.PartialBag {
        layer_name: 'partial_bag_layer',
        dim: *n_hids,
      },
      !obj:pylearn2.models.mlp.Tanh {
        layer_name: 'tanh_layer',
        dim: *n_hids,
        irange: 0.01,
      },
      !obj:pylearn2.models.mlp.Tanh {
        layer_name: 'tanh_layer2',
        dim: *n_hids,
        irange: 0.01,
      },
      !obj:pylearn2.models.mlp.Linear {
        layer_name: 'linear_layer',
        dim: 620,
        irange: 0.01,
        use_cosine_loss: True
      }
    ],
  },
  algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
    learning_rate: .000001,
    learning_rule: !obj:pylearn2.training_algorithms.learning_rule.AdaDelta {},
    batch_size:  32,
    monitoring_dataset: {
      valid: !obj:pylearn2.sandbox.nlp.datasets.translationChars.TranslationChars {
        which_set: 'valid',
        #start: 
        #stop: 2000
      },
      train: !obj:pylearn2.sandbox.nlp.datasets.translationChars.TranslationChars {
        which_set: 'train_cost',
        start: 10000,
        stop: 11000,
      },
    },
    cost: !obj:pylearn2.sandbox.rnn.costs.gradient_clipping.GradientClipping {
      clipping_value: 1,
      cost: !obj:pylearn2.costs.mlp.Default {}
    }
  },
  extensions: [
      !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
          save_path: %(best_save_path)s,
          channel_name: 'valid_objective'
      }
  ],
  save_path: %(save_path)s,
  save_freq: 1
}
